# -*- coding: utf-8 -*-
"""variable-classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Su23kPkXhohw0DTA6JzLWzo0Mi9bOtZ9
"""

# You need TF 1.13.1 to deploy this on AI Platform 
#!pip install tensorflow==1.13.1

import tensorflow as tf 
import pandas as pd
import numpy as np 
import time
from flask import Flask
import shap
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.utils import shuffle



def create_model(vocab_size, num_tags):
  VOCAB_SIZE=400
  model = tf.keras.models.Sequential()
  model.add(tf.keras.layers.Dense(50, input_shape=(VOCAB_SIZE,), activation='relu'))
  model.add(tf.keras.layers.Dense(25, activation='relu'))
  model.add(tf.keras.layers.Dense(num_tags, activation='sigmoid'))

  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
  return model

def add_data(inp, tags):
  f=open("vardata.csv","a+")
  ret=inp.replace("\n", "")
  ret=ret.replace("\t", "")
  ret=ret.replace(",", "")
  f.write("\n")
  f.write(ret)
  f.write(", " + tags)
  f.close()


app= Flask(__name__)
app.run 




@app.route('/getString/<inp_str>')
def getString(inp_str):
  
  f= open("vardata.csv","w+")
  f.write("'text', 'tags'")
  f.close()

  
  input_str=''' public class ListNode
   {
           // instance variables

          // the data to store in this node
          private Object myData;

          // the link to the next node (presumably in a list)
          private ListNode myNext;

          /**
           * default constructor
           * pre: none<br>
           * post: getData() = null, getNext() = null
           */
          public ListNode()
          {	this(null, null);
          }

          /**
           * create a ListNode that holds the specified data and refers to the specified next element
           * pre: none<br>
           * post: getData() = item, getNext() = next
           * @param item the  data this ListNode should hold
           * @param next the next node in the list
           */
          public ListNode(Object data, ListNode next)
          {	x = data;
                  myNext = next;
          }'''

  input_str=inp_str



    

  #list of possible tags:
  ["int itr str lim data func tmp ret"]

  #for all strings in file, add them to the csv
  #for i in range(1000):
     # add_data("for int i =0; i < x ; i++;", "itr lim")
      
  add_data("""public class Factorial
  {
          public static void main(String[] args)
          {	final int x = 100;
                  for(int i = 0; i < x ; i++)
                          System.out.println( i + "! is " + factorial(i));
          }
          
          public static int factorial(int n)
          {	int result = 1;
                  for(int i = 2; i <= n; i++)
                          result *= i;
                  return result;
          }
  }""", "itr lim ret int")

  add_data('''/**
   * A class that represents a node to be used in a linked list.
   * These nodes are singly linked.
   *
   * @author Mike Scott
   * @version July 27, 2005
   */

   public class ListNode
   {
           // instance variables

          // the data to store in this node
          private Object myData;

          // the link to the next node (presumably in a list)
          private ListNode myNext;

          /**
           * default constructor
           * pre: none<br>
           * post: getData() = null, getNext() = null
           */
          public ListNode()
          {	this(null, null);
          }

          /**
           * create a ListNode that holds the specified data and refers to the specified next element
           * pre: none<br>
           * post: getData() = item, getNext() = next
           * @param item the  data this ListNode should hold
           * @param next the next node in the list
           */
          public ListNode(Object data, ListNode next)
          {	x = data;
                  myNext = next;
          }

          
          /**
           * return the data in this node
           * pre: none<br>
           * @return the data this ListNode holds
           */
          public Object getData()
          {	return x ;	}

          
          /**
           * return the ListNode this ListNode refers to
           * pre: none<br>
           * @return the ListNode this ListNode refers to (normally the next one in a list)
           */
          public ListNode getNext()
          {	return myNext;	}


          /**
           * set the data in this node
           * The old data is over written.<br>
           * pre: none<br>
           * @param data the new data for this ListNode to hold
           */
          public void setData(Object data)
          {	x = data;	}

          /**
           * set the next node this ListNode refers to
           * pre: none<br>
           * @param next the next node this ListNode should refer to
           */
          public void setNext(ListNode next)
          {	myNext = next;	}
   }''', 'data itr')


  add_data("""/* CallingMethodsInSameClass.java
   *
   * illustrates how to call static methods a class
   * from a method in the same class
   */

  public class CallingMethodsInSameClass
  {
          public static void main(String[] args) {
                  printOne();
                  printOne();
                  printTwo();
          }

          public static void printOne() {
                  System.out.println("Hello World");
          }

          public static void printTwo() {
                  printOne();
                  printOne();
          }
  }""", 'str ret')

  add_data('''import java.math.BigInteger;
  import java.util.Random;

  public class PrimeEx {

          /**
           * @param args
           */
          public static void main(String[] args) {
                  printTest(10, 4);
                  printTest(2, 2);
                  printTest(54161329, 4);
                  printTest(1882341361, 2);
                  printTest(36, 9);

                  System.out.println(isPrime(54161329) + " expect false");
                  System.out.println(isPrime(1882341361) + " expect true");
                  System.out.println(isPrime(2) + " expect true");
                  int numPrimes = 0;
                  Stopwatch s = new Stopwatch();
                  s.start();
                  for(int i = 2; i < 10000000; i++) {
                          if(isPrime(i)) {
                                  numPrimes++;
                          }
                  }
                  s.stop();
                  System.out.println(numPrimes + " " + s);
                  s.start();
                  boolean[] primes = getPrimes(10000000);
                  int np = 0;
                  for(boolean b : primes)
                          if(b)
                                  np++;
                  s.stop();
                  System.out.println(np + " " + s);

                  System.out.println(new BigInteger(1024, 10, new Random()));
          }

          public static boolean[] getPrimes(int max) {
                  boolean[] result = new boolean[max + 1];
                  for(int i = 2; i < result.length; i++)
                          result[i] = true;
                  final double LIMIT = Math.sqrt(max);
                  for(int i = 2; i <= LIMIT; i++) {
                          if(result[i]) {
                                  // cross out all multiples;
                                  int index = 2 * i;
                                  while(index < result.length){
                                          result[index] = false;
                                           index += i;
                                  }
                          }
                  }
                  return result;
          }


          public static void printTest(int num, int expectedFactors) {
                  Stopwatch st = new Stopwatch();
                  st.start();
                  int actualFactors = numFactors(num);
                  st.stop();
                  System.out.println("Testing " + num + " expect " + expectedFactors + ", " +
                                  "actual " + actualFactors);
                  if(actualFactors == expectedFactors)
                          System.out.println("PASSED");
                  else
                          System.out.println("FAILED");
                  System.out.println(st.time());
          }

          // pre: num >= 2
          public static boolean isPrime(int num) {
                  assert num >= 2 : "failed precondition. num must be >= 2. num: " + num;
                  final double LIMIT = Math.sqrt(num);
                  boolean isPrime = (num == 2) ? true : num % 2 != 0;
                  int div = 3;
                  while(div <= LIMIT && isPrime) {
                          isPrime = num % div != 0;
                          div += 2;
                  }
                  return isPrime;
          }

          // pre: num >= 2
          public static int numFactors(int num) {
                  assert num >= 2 : "failed precondition. num must be >= 2. num: " + num;
                  int result = 0;
                  final double SQRT = Math.sqrt(num);
                  for(int i = 1; i < SQRT; i++) {
                          if(num % i == 0) {
                                  result += 2;
                          }
                  }
                  if(num % SQRT == 0)
                          result++;
                  return result;
          }

  }
  ''', "itr lim int ret")

  #!gsutil cp 'gs://cloudml-demo-lcm/SO_ml_tags_avocado_188k_v2.csv' ./                            8231

  # Read, shuffle, and preview the data
  data = pd.read_csv('vardata.csv', names=['text', 'tags'], header=0)
  data.head()

  """## Downloading and preprocessing data"""

  # Encode top tags to multi-hot
  tags_split = [tags.split(' ') for tags in data['tags'].values]
  print(tags_split)

  tag_encoder = MultiLabelBinarizer()
  tags_encoded = tag_encoder.fit_transform(tags_split)
  num_tags = len(tags_encoded[0])
  print(data['text'].values[0])
  print(tag_encoder.classes_)
  print(tags_encoded[0])

  # Split our data into train and test sets
  train_size = int(len(data) * .8)
  print ("Train size: %d" % train_size)
  print ("Test size: %d" % (len(data) - train_size))

  # Split our labels into train and test sets
  train_tags = tags_encoded[:train_size]
  test_tags = tags_encoded[train_size:]

  # Commented out IPython magic to ensure Python compatibility.
  # # Pre-processing data: create our tokenizer class
  # %%writefile preprocess.py
  # 
  # from tensorflow.keras.preprocessing import text
  # 
  # class TextPreprocessor(object):
  #   def __init__(self, vocab_size):
  #     self._vocab_size = vocab_size
  #     self._tokenizer = None
  #   
  #   def create_tokenizer(self, text_list):
  #     tokenizer = text.Tokenizer(num_words=self._vocab_size)
  #     tokenizer.fit_on_texts(text_list)
  #     self._tokenizer = tokenizer
  # 
  #   def transform_text(self, text_list):
  #     text_matrix = self._tokenizer.texts_to_matrix(text_list)
  #     return text_matrix

  # Create vocab from training corpus
  from preprocess import TextPreprocessor

  VOCAB_SIZE=400 # This is a hyperparameter, try out different values for your dataset

  train_qs = data['text'].values[:train_size]
  test_qs = data['text'].values[train_size:]

  processor = TextPreprocessor(VOCAB_SIZE)
  processor.create_tokenizer(train_qs)

  body_train = processor.transform_text(train_qs)
  body_test = processor.transform_text(test_qs)

  # Preview the first input from our training data
  print(len(body_train[0]))
  print(body_train[0])

  """## Building and training our model"""

  # Save the processor state of the tokenizer
  import pickle

  with open('./processor_state.pkl', 'wb') as f:
    pickle.dump(processor, f)



  model = create_model(VOCAB_SIZE, num_tags)
  model.summary()

  # Train and evaluate the model
  model.fit(body_train, train_tags, epochs=3, batch_size=128, validation_split=0.1)
  print('Eval loss/accuracy:{}'.format(
    model.evaluate(body_test, test_tags, batch_size=128)))

  # Export the model to a file
  model.save('keras_saved_model.h5')

  """## Test our model locally"""

  # Commented out IPython magic to ensure Python compatibility.
  # # Use custom model prediction to save our model + tokenizer
  # %%writefile model_prediction.py
  # import pickle
  # import os
  # import numpy as np
  # 
  # class CustomModelPrediction(object):
  # 
  #   def __init__(self, model, processor):
  #     self._model = model
  #     self._processor = processor
  #   
  #   def predict(self, instances, **kwargs):
  #     preprocessed_data = self._processor.transform_text(instances)
  #     predictions = self._model.predict(preprocessed_data)
  #     return predictions.tolist()
  # 
  #   @classmethod
  #   def from_path(cls, model_dir):
  #     import tensorflow.keras as keras
  #     model = keras.models.load_model(
  #       os.path.join(model_dir,'keras_saved_model.h5'))
  #     with open(os.path.join(model_dir, 'processor_state.pkl'), 'rb') as f:
  #       processor = pickle.load(f)
  # 
  #     return cls(model, processor)

  test_requests = [
    "How to preprocess strings in Keras models Lambda layer? I have the problem that the value passed on to the Lambda layer (at compile time) is a placeholder generated by keras (without values). When the model is compiled, the .eval () method throws the error: You must feed a value for placeholder tensor 'input_1' with dtype string and shape [?, 1] def text_preprocess(x): strings = tf.keras.backend.eval(x) vectors = [] for string in strings: vector = string_to_one_hot(string.decode('utf-8')) vectors.append(vector) vectorTensor = tf.constant(np.array(vectors),dtype=tf.float32) return vectorTensor input_text = Input(shape=(1,), dtype=tf.string) embedding = Lambda(text_preprocess)(input_text) dense = Dense(256, activation='relu')(embedding) outputs = Dense(2, activation='softmax')(dense) model = Model(inputs=[input_text], outputs=outputs) model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy']) model.summary() model.save('test.h5') If I pass a string array into the input layer statically, I can compile the model, but I get the same error if I want to convert the model to tflite. #I replaced this line: input_text = Input(shape=(1,), dtype=tf.string) #by this lines: test = tf.constant(['Hello', 'World']) input_text = Input(shape=(1,), dtype=tf.string, tensor=test) #but calling this ... converter = TFLiteConverter.from_keras_model_file('string_test.h5') tfmodel = converter.convert() #... still leads to this error: InvalidArgumentError: You must feed a value for placeholder tensor 'input_3' with dtype string and shape [2] [[{{node input_3}}]] ",
    "Change the bar item name in Pandas I have a test excel file like: df = pd.DataFrame({'name':list('abcdefg'), 'age':[10,20,5,23,58,4,6]}) print (df) name  age 0    a   10 1    b   20 2    c    5 3    d   23 4    e   58 5    f    4 6    g    6 I use Pandas and matplotlib to read and plot it: import pandas as pd import numpy as np import matplotlib.pyplot as plt import os excel_file = 'test.xlsx' df = pd.read_excel(excel_file, sheet_name=0) df.plot(kind='bar') plt.show() the result shows: enter image description here it use index number as item name, how can I change it to the name, which stored in column name?"
  ]

  from model_prediction import CustomModelPrediction

  ##classifier = CustomModelPrediction.from_path('.')
  ##results = classifier.predict(test_requests)
  ##print(results)
  ##
  ##for i in range(len(results)):
  ##  print('Predicted labels:')
  ##  for idx,val in enumerate(results[i]):
  ##    if val > 0.7:
  ##      print(tag_encoder.classes_[idx])
  ##  print('\n')

  """## Interpreting our model with SHAP"""

  #!pip install shap
  #!pip install colored

  
  attrib_data = body_train[:200]
  explainer = shap.DeepExplainer(model, attrib_data)

  num_explanations = 25
  shap_vals = explainer.shap_values(body_test[:num_explanations])

  words = processor._tokenizer.word_index

  word_lookup = list()
  for i in words.keys():
    word_lookup.append(i)

  word_lookup = [''] + word_lookup
  print(word_lookup[:100])


  test_results=[]
  test_results.append(input_str)
  classifier = CustomModelPrediction.from_path('.')
  results=classifier.predict(test_results)
  print(results)

  stri=str(results)



  for i in range(len(results)):
    print('Predicted labels:')
    for idx,val in enumerate(results[i]):
      if val > 0.5:
        print(tag_encoder.classes_[idx])
    print('\n')




  shap.summary_plot(shap_vals, feature_names=word_lookup, class_names=tag_encoder.classes_)

  return stri


getString("weird string java")
